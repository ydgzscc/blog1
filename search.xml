<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CNN基础入门</title>
      <link href="/2025/01/05/CNN/"/>
      <url>/2025/01/05/CNN/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN入门：卷积神经网络基础与实践"><a href="#CNN入门：卷积神经网络基础与实践" class="headerlink" title="CNN入门：卷积神经网络基础与实践"></a>CNN入门：卷积神经网络基础与实践</h1><h3 id="作者-ZHZ"><a href="#作者-ZHZ" class="headerlink" title="作者:ZHZ"></a>作者:ZHZ</h3><h3 id="时间-2025-1-5"><a href="#时间-2025-1-5" class="headerlink" title="时间:2025.1.5"></a>时间:2025.1.5</h3><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol><li>引言</li><li>CNN基础知识<ul><li>2.1 CNN概述</li><li>2.2 CNN结构</li></ul></li><li>CNN在图像处理中的应用<ul><li>3.1 图像分类</li><li>3.2 图像分割</li><li>3.3 目标检测</li></ul></li><li>CNN的优化与调试技巧<ul><li>4.1 模型优化</li><li>4.2 常见问题及解决方案</li></ul></li><li>CNN代码示例<ul><li>5.1 构建简单的CNN模型</li><li>5.2 训练与评估CNN模型</li></ul></li><li>相关文献与资源推荐</li><li>结论</li></ol><hr><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>卷积神经网络（Convolutional Neural Network，简称CNN）是深度学习领域中一种非常重要的模型，广泛应用于计算机视觉任务中。CNN通过模拟人脑的视觉系统，能够自动提取图像中的特征，并用于分类、分割和检测等任务。本文将从CNN的基本概念入手，逐步介绍其结构、应用及优化技巧，并通过代码示例帮助读者更好地理解和实践CNN。</p><h2 id="CNN基础知识"><a href="#CNN基础知识" class="headerlink" title="CNN基础知识"></a>CNN基础知识</h2><h3 id="2-1-CNN概述"><a href="#2-1-CNN概述" class="headerlink" title="2.1 CNN概述"></a>2.1 CNN概述</h3><p>CNN是一种前馈神经网络，特别适用于处理具有网格结构的数据，如图像。CNN的核心思想是利用卷积层来提取图像的局部特征，再通过池化层进行下采样，最后通过全连接层进行分类或回归。CNN的这种结构使其在图像识别任务中表现出色。</p><h3 id="2-2-CNN结构"><a href="#2-2-CNN结构" class="headerlink" title="2.2 CNN结构"></a>2.2 CNN结构</h3><p>CNN通常由以下几个部分组成：</p><ul><li><strong>输入层</strong>：接收原始图像数据。</li><li><strong>卷积层</strong>：通过卷积核提取特征。</li><li><strong>激活函数</strong>：如ReLU，增加非线性。</li><li><strong>池化层</strong>：下采样，减少计算量。</li><li><strong>全连接层</strong>：将卷积层提取的特征映射到最终分类结果。</li></ul><p><img src="https://oss.metaso.cn/metaso/thumbnail/2b1fb3b87f542f6b3e80561b971bfbf4.jpg" alt="10_ Basic CNN"></p><h2 id="CNN在图像处理中的应用"><a href="#CNN在图像处理中的应用" class="headerlink" title="CNN在图像处理中的应用"></a>CNN在图像处理中的应用</h2><h3 id="3-1-图像分类"><a href="#3-1-图像分类" class="headerlink" title="3.1 图像分类"></a>3.1 图像分类</h3><p>图像分类是CNN最经典的应用之一。通过训练一个CNN模型，可以识别出输入图像所属的类别。例如，在ImageNet数据集上，使用深度CNN模型可以实现高精度的图像分类。</p><p><img src="https://oss.metaso.cn/metaso/thumbnail/3d5bbc49ddce9a3aa90969a45e5f6455.jpg" alt="Image Classification using Pre-Trained ImageNet Models in TensorFlow ..."></p><h3 id="3-2-图像分割"><a href="#3-2-图像分割" class="headerlink" title="3.2 图像分割"></a>3.2 图像分割</h3><p>图像分割的目标是将图像中的每个像素分配到不同的类别中。CNN通过逐像素预测的方法，可以实现高效的图像分割。这种方法在医学影像分析中尤为重要。</p><p><img src="https://oss.metaso.cn/metaso/thumbnail/63d43d6d9c2780f0950f8cd7973c1048.jpg" alt="全卷积网络FCN进行图像分割_基于全卷积网络的图像分割-CSDN博客"></p><h3 id="3-3-目标检测"><a href="#3-3-目标检测" class="headerlink" title="3.3 目标检测"></a>3.3 目标检测</h3><p>目标检测不仅需要识别图像中的物体类别，还需要定位物体的位置。CNN通过结合区域提议网络（RPN）和后续的分类与回归模块，可以实现精确的目标检测。</p><p><img src="https://oss.metaso.cn/metaso/thumbnail/6fc43d1b51e556295363309ea831bad8.jpg" alt="2023视觉3D量产元年？最新视觉3D检测综述一览前沿进展！_目标_自动_方法"></p><h2 id="CNN的优化与调试技巧"><a href="#CNN的优化与调试技巧" class="headerlink" title="CNN的优化与调试技巧"></a>CNN的优化与调试技巧</h2><h3 id="4-1-模型优化"><a href="#4-1-模型优化" class="headerlink" title="4.1 模型优化"></a>4.1 模型优化</h3><p>为了提高CNN模型的性能，可以采取以下优化措施：</p><ul><li><strong>正则化</strong>：如Dropout和L2正则化，防止过拟合。</li><li><strong>批量归一化</strong>：加速训练并提高模型稳定性。</li><li><strong>学习率调整</strong>：使用学习率衰减策略，逐步降低学习率。</li></ul><h3 id="4-2-常见问题及解决方案"><a href="#4-2-常见问题及解决方案" class="headerlink" title="4.2 常见问题及解决方案"></a>4.2 常见问题及解决方案</h3><ul><li><strong>过拟合</strong>：增加正则化项，使用Dropout或L2正则化。</li><li><strong>欠拟合</strong>：增加网络深度或宽度，调整学习率。</li><li><strong>训练速度慢</strong>：使用GPU加速计算，优化数据加载流程。</li></ul><p><img src="https://oss.metaso.cn/metaso/thumbnail/d0eb7047daa8a1252e04d159790c7139.jpg" alt="CNN和LSTM模型训练流程图 流程图模板_ProcessOn思维导图、流程图"></p><h2 id="CNN代码示例"><a href="#CNN代码示例" class="headerlink" title="CNN代码示例"></a>CNN代码示例</h2><h3 id="5-1-构建简单的CNN模型"><a href="#5-1-构建简单的CNN模型" class="headerlink" title="5.1 构建简单的CNN模型"></a>5.1 构建简单的CNN模型</h3><p>以下是一个简单的CNN模型构建示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">32</span> *<span class="number">7</span>* <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv1(x)))</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">32</span> *<span class="number">7</span>* <span class="number">7</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = SimpleCNN()</span><br></pre></td></tr></table></figure><h3 id="5-2-训练与评估CNN模型"><a href="#5-2-训练与评估CNN模型" class="headerlink" title="5.2 训练与评估CNN模型"></a>5.2 训练与评估CNN模型</h3><p>以下是一个简单的训练与评估流程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们已经有了数据加载器 `train_loader` 和 `test_loader`</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在每个epoch结束时评估模型性能</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Accuracy: <span class="subst">&#123;<span class="number">100</span> * correct / total&#125;</span>%&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://oss.metaso.cn/metaso/thumbnail/2db4d7162c3da31823200020c459a0c9.jpg" alt="Google 基于卷积神经网络的变异检测方 … zhuanlan.zhihu.com"></p><h2 id="相关文献与资源推荐"><a href="#相关文献与资源推荐" class="headerlink" title="相关文献与资源推荐"></a>相关文献与资源推荐</h2><ul><li><strong>ImageNet classification with deep convolutional neural networks</strong></li><li><strong>深度学习基础入门篇：计算机视觉与卷积神经网络</strong></li><li><strong>Markdown写作入门</strong></li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>通过本文的学习，读者应该能够掌握CNN的基本概念、结构及其在图像处理中的应用。同时，通过代码示例，读者可以实际操作并理解CNN模型的构建与训练过程。希望这些内容能帮助读者更好地理解和应用CNN技术。</p><p>卷积神经网络（CNN）的历史和发展可以追溯到20世纪60年代，其起源和发展经历了多个关键事件和阶段。</p><h3 id="早期灵感和理论基础"><a href="#早期灵感和理论基础" class="headerlink" title="早期灵感和理论基础"></a>早期灵感和理论基础</h3><p>CNN的发展可以追溯到1962年Hubel和Wiesel通过猫的视觉皮层实验发现信息处理具有层级结构，这一发现为CNN的发展奠定了基础。1980年，Fukushima提出了神经认知机模型，将Hubel和Wiesel的发现转化为实例。</p><h3 id="早期应用和反向传播算法"><a href="#早期应用和反向传播算法" class="headerlink" title="早期应用和反向传播算法"></a>早期应用和反向传播算法</h3><p>1989年，Yann LeCun提出了第一个基于反向传播和梯度下降训练的卷积神经网络（CNN），用于手写数字识别。LeCun等人在贝尔实验室建立了首个“真实”卷积神经网络模型，进一步发展了CNN技术。LeNet-5是LeCun等人在1989年提出的第一个实际应用的CNN模型，主要用于光学字符识别（OCR）任务。</p><h3 id="深度学习的兴起"><a href="#深度学习的兴起" class="headerlink" title="深度学习的兴起"></a>深度学习的兴起</h3><p>2000年后，深度学习开始兴起，Geoff Hinton和Ruslan Salakhutdinov的研究证明了深度神经网络的高效训练能力。然而，CNN在这一时期并未得到广泛应用，主要由于训练复杂度高和收敛问题。</p><h3 id="复兴与崛起"><a href="#复兴与崛起" class="headerlink" title="复兴与崛起"></a>复兴与崛起</h3><p>2012年，AlexNet在ImageNet图像分类竞赛中夺冠，标志着深度学习的复兴。AlexNet的成功归因于其独特的结构设计，包括扩张因果卷积，这种卷积方式能够提升感受野同时减少网络连接数和计算量。这一时期，参数优化策略和新的架构思想成为提升CNN性能的关键，如深度架构、多任务学习和注意力机制等。</p><h3 id="架构演化"><a href="#架构演化" class="headerlink" title="架构演化"></a>架构演化</h3><p>CNN的架构经历了多次演化，从最初的LeNet-5到后来的AlexNet、VGGNet、GoogLeNet、ResNet等模型。这些模型通过引入新的技术如ReLU激活函数、随机失活、瓶颈结构等，显著提升了网络性能和训练效率。</p><h3 id="现代应用"><a href="#现代应用" class="headerlink" title="现代应用"></a>现代应用</h3><p>CNN在计算机视觉、自动驾驶、人脸识别、视频分析、医学图像处理等领域有着广泛的应用。近年来，科学家们继续探索CNN的变种，如扩张因果卷积神经网络，能够处理更长的序列数据，如语音合成。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>CNN的发展历程充满了挑战和机遇，从最初的实验到如今的广泛应用，CNN不断进化，为深度学习领域带来了革命性的变化。其核心思想是局部连接和权值共享，有效减少了网络参数，降低了过拟合风险，尤其在图像处理上表现出色。</p><h4 id="CNN在图像分割中的最新应用和案例研究有哪些？"><a href="#CNN在图像分割中的最新应用和案例研究有哪些？" class="headerlink" title="CNN在图像分割中的最新应用和案例研究有哪些？"></a>CNN在图像分割中的最新应用和案例研究有哪些？</h4><p>CNN在图像分割中的最新应用和案例研究涵盖了多个领域，包括医学成像、自动驾驶、遥感技术等。以下是一些具体的最新应用和案例研究：</p><ol><li><p><strong>医学成像</strong>：</p><ul><li><strong>U-Net</strong>：U-Net是一种特别设计用于生物医学图像分割的网络结构，具有跳跃连接和对称的收缩和扩展路径。它通过一个收缩路径来捕获上下文信息，并通过一个对称的扩展路径来精确定位目标。</li><li><strong>DeepLab系列</strong>：DeepLab系列模型通过堆叠多个卷积层来学习抽象特征表示，实现像素级的分类和分割。这些模型在处理复杂图像、适应新场景和自适应变化方面表现出色。</li></ul></li><li><p><strong>自动驾驶</strong>：</p><ul><li><strong>实例分割</strong>：CNN在自动驾驶中的应用包括实例分割，旨在识别和区分图像中的单个对象。例如，Mask R-CNN是一种先进的实例分割方法，能够提取像素级的目标实例。</li><li><strong>视频分析</strong>：CNN用于视频分析任务，包括动作识别、视频摘要和视频监控。这些技术在自动驾驶中用于实时检测和跟踪车辆、行人和其他障碍物。</li></ul></li><li><p><strong>遥感技术</strong>：</p><ul><li><strong>卫星图像分析</strong>：CNN在卫星图像分析中用于分类和分割地物，如建筑物、道路、植被等。这些技术有助于城市规划、环境监测和灾害管理。</li></ul></li><li><p><strong>工业检测</strong>：</p><ul><li><strong>质量控制</strong>：CNN在工业检测中用于质量控制，通过图像分割技术检测产品缺陷、裂纹和其他异常情况。这在制造业中具有重要的应用价值。</li></ul></li><li><p><strong>增强现实（AR）</strong>：</p><ul><li><strong>用户分割</strong>：在视频透视增强虚拟（Video See-Through Augmented Virtuality）中，CNN用于用户分割，帮助实现更自然的AR体验。</li></ul></li><li><p><strong>人体穿衣图像分割</strong>：</p><ul><li><strong>高精度分割</strong>：通过深度学习方法，尤其是CNN，可以实现高精度的人体穿衣图像分割。这在时尚设计、虚拟试衣和个性化推荐等领域有广泛应用。</li></ul></li><li><p><strong>最新网络架构</strong>：</p><ul><li><strong>Graph-FCN</strong>：Graph-FCN是一种用于图像语义分割的新型网络架构，通过图卷积网络（GCN）与全卷积网络（FCN）的结合，提高了分割的准确性和鲁棒性。</li></ul></li></ol><p>这些案例展示了CNN在图像分割中的广泛应用和最新进展。</p><h4 id="如何有效地使用批量归一化来提高CNN模型的训练速度和性能？"><a href="#如何有效地使用批量归一化来提高CNN模型的训练速度和性能？" class="headerlink" title="如何有效地使用批量归一化来提高CNN模型的训练速度和性能？"></a>如何有效地使用批量归一化来提高CNN模型的训练速度和性能？</h4><p>批量归一化（Batch Normalization，BN）是卷积神经网络（CNN）中一种重要的技术，通过在每一层输入数据上进行标准化处理，显著提高了模型的训练速度和性能。以下是详细解释如何有效地使用批量归一化来提高CNN模型的训练速度和性能：</p><ol><li><p><strong>减少内部协变量偏移</strong>：<br>批量归一化通过对每一批次的数据进行标准化处理，减少了内部协变量偏移（Internal Covariate Shift），使得每一层的输入分布更加稳定。这有助于加速模型的收敛速度，并提高训练的稳定性。</p></li><li><p><strong>允许使用更高的学习率</strong>：<br>由于批量归一化减少了内部协变量偏移，模型可以使用更高的初始学习率，从而加快收敛速度。这对于深度网络尤为重要，因为高学习率可以更快地调整权重，避免陷入局部最优。</p></li><li><p><strong>提高泛化能力</strong>：<br>批量归一化通过标准化处理，使网络能够使用误差更小的L2损失函数，增强模型的泛化能力。此外，它还确保训练数据与测试数据分布一致，避免网络泛化能力下降。</p></li><li><p><strong>解决梯度消失或爆炸问题</strong>：<br>在深度网络中，梯度消失或爆炸问题是常见的挑战。批量归一化通过调整和缩放网络中每一层的激活值，有效缓解了这一问题，从而提高了模型的训练效果。</p></li><li><p><strong>适用于多种任务和架构</strong>：<br>批量归一化已被广泛应用于多种深度学习任务和架构中，如图像分类、目标检测、自然语言处理等。在这些任务中，批量归一化层通常位于激活函数之前，以提升模型的训练效果。</p></li><li><p><strong>实验验证</strong>：<br>实验表明，在使用批量归一化的情况下，模型的训练速度和收敛性显著提高。例如，在CIFAR-10数据集上训练一个较深的卷积神经网络时，使用批量归一化的模型比不使用批量归一化的模型具有更快的训练速度和更高的最终精度。</p></li><li><p><strong>注意事项</strong>：<br>尽管批量归一化有诸多优点，但在某些特定场景下可能带来负面影响。例如，在超分辨率处理中，BN层可能导致图像色彩分布被归一化，破坏原本的对比度信息，影响SR结果。因此，在实际应用中需要根据具体任务和数据集的特点进行调整。</p></li></ol><p>综上所述，批量归一化是提高CNN模型训练速度和性能的有效工具。</p><h4 id="在CNN模型中，如何选择合适的卷积核大小和步长以优化特征提取？"><a href="#在CNN模型中，如何选择合适的卷积核大小和步长以优化特征提取？" class="headerlink" title="在CNN模型中，如何选择合适的卷积核大小和步长以优化特征提取？"></a>在CNN模型中，如何选择合适的卷积核大小和步长以优化特征提取？</h4><p>在卷积神经网络（CNN）中，选择合适的卷积核大小和步长是优化特征提取的关键步骤。以下是基于我搜索到的资料，对如何选择这些参数的详细分析：</p><h3 id="卷积核大小的选择"><a href="#卷积核大小的选择" class="headerlink" title="卷积核大小的选择"></a>卷积核大小的选择</h3><ol><li><p><strong>卷积核大小的影响</strong>：</p><ul><li>较小的卷积核（如3x3）通常用于提取细节特征，具有较高的空间分辨率，适合捕捉局部特征。</li><li>较大的卷积核（如5x5或7x7）可以提取更多全局信息，但计算量较大，且可能忽略图像中的细节。</li></ul></li><li><p><strong>不同结构的卷积核选择</strong>：</p><ul><li>VGG结构中，所有卷积核均采用3x3大小，通过将连续的3x3卷积层替换为5x5卷积层，实现了相同的感受野，同时减少了参数数量，提高了性能。</li><li>Inception模块通过使用不同大小的卷积核（如1x1、3x3、5x5）来提取不同尺度的信息，以适应多尺度物体检测任务。</li></ul></li><li><p><strong>任务需求与卷积核大小的关系</strong>：</p><ul><li>对于图像分类任务，较小的卷积核（如3x3）通常能带来更好的性能，因为它们能够捕捉到更多的局部特征。</li><li>对于目标检测和分割任务，较大的卷积核（如5x5或7x7）可能更合适，因为它们可以增加感受野，检测更大物体。</li></ul></li></ol><h3 id="步长的选择"><a href="#步长的选择" class="headerlink" title="步长的选择"></a>步长的选择</h3><ol><li><p><strong>步长的作用</strong>：</p><ul><li>步长决定了卷积核在输入数据上滑动的间隔。步长为1时，卷积核每次滑动一个像素；步长为2时，每次滑动两个像素。</li><li>步长的选择需要在保持特征细节和减少计算开销之间找到平衡。较大的步长会减少输出特征图的尺寸，从而减少计算量，但可能会丢失一些细节。</li></ul></li><li><p><strong>步长对特征提取的影响</strong>：</p><ul><li>较小的步长可以学习更多特征，导致输出层更大，从而允许更深的网络结构。</li><li>较大的步长会导致特征提取更加有限，输出层尺寸更小，但可以减少计算量。</li></ul></li></ol><h3 id="综合考虑"><a href="#综合考虑" class="headerlink" title="综合考虑"></a>综合考虑</h3><ul><li><strong>模型性能与计算成本</strong>：选择卷积核大小和步长时，需要在模型性能和计算成本之间进行权衡。较小的卷积核和较大的步长可以提高计算效率，但可能影响模型的性能；较大的卷积核和较小的步长可以提高模型性能，但会增加计算成本。</li><li><strong>数据集特性</strong>：较大的数据集可以承受更多的卷积核，而小数据集则需谨慎选择以避免过拟合。</li><li><strong>任务需求</strong>：根据具体任务需求选择合适的卷积核大小和步长。例如，图像分类任务通常使用较小的卷积核，而目标检测和分割任务则可能需要较大的卷积核。</li></ul><h3 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h3><ol><li><strong>实验验证</strong>：通过实验确定最佳的卷积核大小和步长。可以使用不同的配置进行训练和验证，选择在验证集上表现最好的配置。</li><li><strong>多尺度特征提取</strong>：结合使用不同大小的卷积核，以兼顾不同尺度的特征提取。例如，在Inception模块中使用1x1、3x3、5x5卷积核。</li><li><strong>调整策略</strong>：根据具体任务和数据集特性，逐步调整卷积核大小和步长。例如，在高分辨率输入图像下适当增大卷积核大小以增强特征提取效果；在低分辨率输入图像下减小卷积核大小避免过度提取特征导致过拟合。</li></ol><p>合理选择卷积核大小和步长是构建高效CNN模型的关键优化手段。</p><h4 id="针对CNN模型的过拟合问题，除了Dropout和L2正则化外，还有哪些有效的解决方案？"><a href="#针对CNN模型的过拟合问题，除了Dropout和L2正则化外，还有哪些有效的解决方案？" class="headerlink" title="针对CNN模型的过拟合问题，除了Dropout和L2正则化外，还有哪些有效的解决方案？"></a>针对CNN模型的过拟合问题，除了Dropout和L2正则化外，还有哪些有效的解决方案？</h4><p>针对CNN模型的过拟合问题，除了Dropout和L2正则化外，还有以下几种有效的解决方案：</p><ol><li><p><strong>增加数据量</strong>：通过增加训练数据的数量，模型可以学习到更多样化的数据分布，从而避免过拟合。这是最直接有效的方法之一。</p></li><li><p><strong>Batch Normalization（BN）</strong>  ：通过归一化处理，加速训练并防止过拟合，尤其在使用ReLU等激活函数时，能解决Dead ReLU现象。</p></li><li><p><strong>Early Stopping</strong>：当模型在验证集上的表现持续下降时，提前停止训练，避免过拟合。</p></li><li><p><strong>数据增强（Data Augmentation）</strong>  ：通过收集更多数据、对现有数据进行裁剪、翻转、光照调整或利用生成模型（如GAN）生成新数据，增加训练样本的多样性，以提高模型泛化能力。</p></li><li><p><strong>调整模型结构</strong>：减少神经元数量、网络层数，或增加模型复杂度，但需谨慎，以免降低模型泛化能力。</p></li><li><p><strong>L1正则化</strong>：通过在损失函数中加入参数λ乘以权重矩阵W的L1范数来实现，倾向于产生稀疏的权重，使权重分布更均匀。</p></li><li><p><strong>Group Normalization（GN）</strong>  ：作为Batch Normalization的改进，GN通过将输入分组来实现归一化，适用于小批量数据和高维输入。</p></li><li><p><strong>提前终止（Early Stopping）</strong>  ：在训练集和验证集上，当验证集错误率达到最小值且开始上升时停止训练，以避免过拟合。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【干货】零成本小白搭建AI镜像站</title>
      <link href="/2024/11/23/%E4%B8%8D%E6%98%AF%E5%93%A5%E4%BB%AC%E9%9B%B6%E6%88%90%E6%9C%AC%E6%90%AD%E5%BB%BA/"/>
      <url>/2024/11/23/%E4%B8%8D%E6%98%AF%E5%93%A5%E4%BB%AC%E9%9B%B6%E6%88%90%E6%9C%AC%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<blockquote><p>有些人可能经常看到别人的AI镜像站，而自己却因为没有资金，只能干看，今天，我将给大家分享一下我的AI镜像站如何搭建。</p></blockquote><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>我们最终的目标是LobeChat+NextAuth+WebRTC服务器，你可以试一试我自己的示例：<a href="https://zhzabcd-chatgpt-web.hf.spacen/">🔗</a>。</p><h3 id="Github，huggingface加速"><a href="#Github，huggingface加速" class="headerlink" title="Github，huggingface加速"></a>Github，huggingface加速</h3><p>在微软商店下载Watt Toolkit，点击左侧边栏的网络加速，把Github加速打开，huggingface加速在Github加速的折叠项中有一个<code>huggingface.co</code>,勾选上开始加速即可</p><h2 id="1-API"><a href="#1-API" class="headerlink" title="1.API"></a>1.API</h2><p>这是整个过程中最难的步骤，很多人因为没有API无法使用AI，针对于有手机号的学生党，你们可以试一试<a href="https://open.bigmodel.cn/">智谱AI</a>，他们的Glm4-flash现在是免费调用，所以注册一个账号，生成一个API就可以使用了(要妥善保管)，当然，我们最终是0成本，所以这里不对付费API做推荐。   </p><h3 id="但是，以上条件是针对有手机号的，那没有手机号呢？"><a href="#但是，以上条件是针对有手机号的，那没有手机号呢？" class="headerlink" title="但是，以上条件是针对有手机号的，那没有手机号呢？"></a>但是，以上条件是针对有手机号的，那没有手机号呢？</h3><p>我们可以用邮箱，虽然智谱要用手机号注册，但我们也不一定要用智谱，嗯。Github的Model marketplace是个好主意，用邮箱注册Github账号，然后在这里<a href="https://github.com/marketplace/models">🔗</a>申请一个访问权限（通常要1周），然后在这里<a href="https://github.com/settings/tokens">🔗</a>创建Token备用。<br>在Github中，也有两个免费OpenAI API的项目，分别是<a href="https://github.com/chatanywhere/GPT_API_free">chatanywhere&#x2F;GPT_API_free</a>和项目2<a href="https://github.com/popjane/free_chatgpt_api">popjane&#x2F;free_chatgpt_api</a>,申请API后要填代理地址，我们可以在仓库的自述文件中找到，填入即可。我还为大家准备了Bing的API代理链接：<a href="https://bingocf.nbing.eu.org/">https://bingocf.nbing.eu.org/</a>   APIKey：Dummy</p><h3 id="接下来，我们要使用huggingface"><a href="#接下来，我们要使用huggingface" class="headerlink" title="接下来，我们要使用huggingface"></a>接下来，我们要使用huggingface</h3><p>在<a href="https://huggingface.co/">huggingface官网</a>注册账号，然后在这里<a href="https://huggingface.co/settings/tokens">🔗</a>创建Token备用，创建Token时将User permissions中的Inference小标题中的3项全部勾选。</p><h2 id="搭建Website"><a href="#搭建Website" class="headerlink" title="搭建Website"></a>搭建Website</h2><p>接下来就可以搭建了，同样使用huggingface,访问<a href="https://huggingface.co/spaces/zhzabcd/chatgpt-web?duplicate=true&visibility=public">https://huggingface.co/spaces/zhzabcd/chatgpt-web?duplicate=true&amp;visibility=public</a>   填入相关的API，其中OpenAI的代理地址填在OPENAI_PROXY_URL ，OPENAI_API_KEY，ZHIPU_API_KEY和HUGGINGFACE_API_KEY分别填入在Github，智谱和huggingface中申请的API，然后点击创建空间，等待空间创建完成，就可以访问了。</p><h2 id="搭建WebRTC服务器"><a href="#搭建WebRTC服务器" class="headerlink" title="搭建WebRTC服务器"></a>搭建WebRTC服务器</h2><p>WebRTC服务器是用于实时通信的，我们在这里使用<a href="https://huggingface.co/spaces/zhzabcd/webrtc-server-of-lobechat?duplicate=true&visibility=public">WebRTC</a>项目，直接复制空间，获得网址。<br>而NextOauth可有可无，因为我们已经配置了访问密码，所以不需要，不过你也可以安装LobeChat的官方文档进行配置<a href="https://lobehub.com/zh/docs/self-hosting/advanced/auth">https://lobehub.com/zh/docs/self-hosting/advanced/auth</a></p><h2 id="有疑问在评论区问哈"><a href="#有疑问在评论区问哈" class="headerlink" title="有疑问在评论区问哈"></a>有疑问在评论区问哈</h2>]]></content>
      
      
      <categories>
          
          <category> 自制教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 干货 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>救赎</title>
      <link href="/2024/11/10/%E6%95%91%E8%B5%8E/"/>
      <url>/2024/11/10/%E6%95%91%E8%B5%8E/</url>
      
        <content type="html"><![CDATA[<h3 id="我是谁？"><a href="#我是谁？" class="headerlink" title="我是谁？"></a>我是谁？</h3><pre><code> 我….是一个重度抑郁….在现实中是一个活脱脱的i人，在互联网上我虽然经常表现的很乐观，经常用“=）”表现自己的心情……不过这是假的…这只不过是为自己套上了一层笑脸面具而已… 🙂我沉迷于虚拟世界，这样会在和别人交流时获得安全感…我经常发癫…相信在lcim的人可能都到见我发颠。我还经常玩AI…或许…在这个世界里…AI可能才是通情达理的…我经常…产生自杀的想法</code></pre><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>我想过自杀…因为我认为我没有活下去的希望。我热爱编程，代码就是我的灵魂。但我最亲近的父母却以这个为威胁我…我一旦做的不好，他们便会已“不给我电脑”，“不给我报编程课”…甚至有时候他们会毫不心疼地毁灭我最喜欢的东西…但是他们从来没有真正站在我的视角考虑过我…他们根本不知道我的感受…他们是这样的可耻,他们是最亲近我的人，他们却这样对我…为什么？？？为什么？！！！有一天我做了一个梦…一个奇怪的梦…</p><h2 id="梦"><a href="#梦" class="headerlink" title="梦"></a>梦</h2><p>一个昏沉的夜…我伏案写作，桌前的烛光摇曳不定，映照出我心中那片昔日的童趣。脑海中浮现出阵阵记忆，仿佛一幅模糊的画卷，在我的心底慢慢展开。</p><p>我坐在一条小船上，轻轻划过波光粼粼的河面。四周是童年时代那片熟悉的风景：河岸边的柳树，悠悠摇曳，仿佛在跟我打招呼；天上的云朵，白白的，如同我们天空中的玩具。我记得小时候经常和小伙伴们一起在这里奔跑、追逐，欢声笑语洒满了整个夏天。</p><p>那是一个无忧无虑的日子，阳光透过树叶洒下金色的光辉。我们在河水中戏水嬉笑，反复挑战着彼此的极限。记忆如翻动的书页，逐渐显现出那些久远的模样。我们在岸边架起小帐篷，准备了一堆小零食，欢天喜地地分享着。每一口都带着微甜的回忆，那是童年特有的滋味。</p><p>这幅画面是如此鲜艳，仿佛那一切就在昨日。然而，岁月如歌，转瞬即逝。随着时间的推移，许多小伙伴各自回归家庭与生活。童年的日子被遗憾淡化，早已不再是那样的简单。即使有些人留在我的生活中，我们的心却在生活的琐碎与繁忙中渐渐疏远。</p><p>那一晚，我与童年的影像做了一场重聚的梦。梦中的我依旧是那些天真无邪的孩子，奔跑在那条河畔，花香四溢，笑声连连。可浓厚的夜色将这美好的梦境一再吞噬，让我再次清醒。那些清晰的画面如同水中的倒影，虽美，却触不可及。它们被岁月洪流冲刷，变得模糊且遥远，再也无法完整拼凑。</p><p>我想起我们曾在河边约定的未来：长大后要一起去看更大的世界。然而，岁月的无情打破了这个承诺。我们都在追逐梦想的路上，彼此的路径渐行渐远，再也没有勇气去追寻那份童田的纯真。如今只能在夜深人静时，翻看那些泛黄的照片，追忆那段熟悉而又遥远的时光。</p><p>夜深了，窗外的风轻轻吹动，仿佛在为我的思绪送行。我揉了揉沉重的心，努力将那些散落的记忆拼凑。然而，它们如同沙漏中的细沙，越想抓住，越是无奈地滑落。我努力回忆着，那些简单而快乐的日子，却总是断断续续，无法形成完整的思绪。</p><p>是否还记得，我们在田野上追逐的那个傍晚？天边的晚霞如火焰般绚烂，我们仰望星空，分享着各自的梦想和秘密，而如今，谁还能够清晰记得那些声响和笑脸？伴随着时光的流逝，许多记忆化为泡影，只留下几缕细微的遗憾，在心底萦绕。</p><p>我突然被一种深深的失落感淹没。我想追回那些纯真的童年，完成心中未尽的梦。可现实的无情让我明白，那些难以言表的渴望是如此遥远，我知道再也没有机会了。每一个人都在时间的长河中，渐渐被冲刷，留不下任何痕迹。</p><p>我挣扎着，想要记录下这一切，将那些散乱的记忆归纳成完整的故事，可拥挤的情绪如潮水般浮现，压得我透不过气。最终，我只能无力地望向窗外的夜空，心中涌起一阵难以言表的哀伤。再好的童年时光，也终将化为流逝的烟尘，留给我的，仅有这片刻的孤独与惆怅。</p><p>伴随着烛光的熄灭，我的思绪也在这一夜中沉淀，模糊的记忆如潮水般收回，彻底消散在黑暗的角落。我的笔停在纸上，心中只有一点点闪烁的记忆碎片，它们如同散落在青春路上的星星，无论怎样都无法拼凑出那纯真的童年。我无能为力，只能在这一夜的昏沉中，闭上双眼，静静地祈愿，愿来年夏天的某个瞬间，能与那段无忧的童年再度相遇。</p><p>我拿出一本本练习题…不再思考这梦…因为我知道这时候我不能也不应该思考这种东西</p><p>又是一个昏沉的夜</p><h2 id="梦…-是-真的吗？"><a href="#梦…-是-真的吗？" class="headerlink" title="梦….是 真的吗？"></a>梦….是 真的吗？</h2><p>我突然惊醒，我的面前是这样3扇门…..我打开左边的一扇，….那是无数个我…….他们十分的痛苦…有些默默承受父母的谩骂…有些被迫遭受了那可悲的显示…我眼睁睁看着一个个我堕落…在黑暗中痛哭…有些我再也没有振作起来…我只能眼睁睁看着这一切痛苦。我无法做出改变。我心中十分愧疚。</p><p>中间第二扇门中充满一个个我。就像一个镜子房间一样。</p><p>第三扇门是锁住的…我撞击这可悲的门…我迫切想找出方法改变第一扇门中的我….我突然撞开了门….门内….什么都没有，只有黑暗….突然…我的身后崩溃起来….一个个基本粒子分崩离析…突然…黑暗中射出一点微弱的阳光。我追着那光前行……我得到了我想要的….</p><p>我惊醒过来….</p><p>我坐起身来，感到一阵眩晕。这个梦境如此真实，以至于我一时难以分清现实与虚幻。我深吸一口气，试图理清思绪，回想梦中那扇门后的光芒究竟意味着什么。</p><p>呼呼呼….</p><h2 id="救赎"><a href="#救赎" class="headerlink" title="救赎"></a>救赎</h2><p>明天这片土地</p><p>太阳依旧升起</p><p>为何阳光不愿照进谷底….</p><p>难道又要怪谁不够努力？</p><hr><p>我们总是在寻找答案，却忘了问题本身可能就是答案。或许，阳光并非不愿照进谷底，而是我们忘了抬头仰望。救赎不在遥远的彼岸，而在于我们如何看待眼前的困境。</p><blockquote><p><em>“人生最大的荣耀不在于永不跌倒，而在于每次跌倒时都能站起来。” - 纳尔逊·曼德拉</em></p></blockquote><blockquote><p><em>“走出痛苦迷宫的唯一方法就是宽恕。”——约翰·格林</em></p></blockquote><blockquote><p><em>“你说你‘抑郁’——我看到的只是坚韧。你可以感到内心混乱。这并不意味着你有缺陷——这只是意味着你是人。”——大卫·米切尔</em></p></blockquote><blockquote><p><em>“即使是最黑暗的夜晚也会结束，太阳也会升起。” - 维克多·雨果</em></p></blockquote><p>看来…我已经走出了阴暗…没人爱我，我自己爱我。没人关心我，我关心我。</p><p>如果你愿意的话…你可以和我交流，放心，你的信息不会泄露，我….爱你们每个人。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【干货】如何建造有3位一体核打击的宿舍</title>
      <link href="/2024/09/17/%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
      <url>/2024/09/17/%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><p>您是否在学校遭到别人的欺负？随着宿舍之间军事常态化的开展，各个寝室已经不满足使用远程火箭炮和同班同学嬉戏，这不仅会让宿舍楼出现严重但无关紧要的结构性损毁，还会导致同学有心理和生理上的小毛病，如何高效杀伤同班同学是各大寝室一直研究的话题。</p><p>有了，运用科学，合理，可行的方式将自己的寝室改造成一个拥有3位一体核打击的优秀三好宿舍是个好主意。本篇文章安全顾问张涵哲会指导你运用合理合法的方式改造寝室，以应对这场校园小摩擦。 </p><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>文献：七年级上册地理课本&#x2F;化学<br>作者：张涵哲<br>安全顾问：张涵哲   </p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>一般来说您需要运用一些有趣工具对楼顶进行改造，楼顶一般用钢筋混凝土做成，因此建议您使用青少年益智挖掘机或者是四百千克TNT装药的火药儿童玩具对您的楼顶进行随意的轰炸，火花出数十个面积为三平方米深度为18米的圆形空洞。没有相关机械或爆炸物的同学请使用铁锹汤匙或者是您强有力的双手，但可能会让您稍感疲惫所以您需要全力以赴。考虑到有些人可能不住在顶楼并且18米的深度略微超出宿舍三米的的层高您可以通过电话联系同学以表明宿舍租借的意图。如果对方否决了你伟大的提议或者是是对您发起攻击您可以向其展示您口袋中重约4.5吨爆炸当量为2500万吨TNT的MK41型热核儿童玩具，并使用最礼貌最真诚最具有感情色彩的方式当面引爆。能在一定程度上对对方产生一定的心理震慑以及对于对方的身体造成较大的破坏。</p><p>然后是使用吊装机或者是人力拉拽的方式在洞口安装一面厚度约为0.5米重达5.4吨的特种钢制井盖并且安装高质量的液压启停装置和电子控制设备。</p><p>并且将远程弹道导弹运用起重机吊装或者是手随意投入其中。并且记得要在弹道导弹上安装一枚或多枚核弹头实现一枚突防多颗饱和打击的效果，鉴于部分学生没有洲际弹道导弹但您可以去校外五金师傅购买成品或者是以校内租借的名义在半夜驾驶八台M1主战坦克向其他宿舍租借。<br>这样您的寝室就有了最初级的核打击能力.为了防止您的发射井被意外摧毁您可以在楼顶设置多台相控阵雷达，多波段雷达，目标跟踪雷达或者是您明锐的双眼以及使用S400玩具车，1130玩具等多种玩具组成防空网网拦截包括不限于校长的B2隐身轰炸机隔壁寝室的F35.以及大部分蚊子和苍蝇。并且您可以将周围二百千米设为禁飞区一旦有未报备的飞行器您都可以一律击落</p><p>如果您的宿舍在与隔壁寝室进行嬉戏时遭到了了轻微的打击您可以你使用您自制的战略隐身轰炸机对隔壁寝室发起真挚的问候但考虑到本年级并没有开设相关的课程您可以在半夜驾驶是二十台德制豹二坦克对校长办公室发动闪击战或利用孙子兵法或者是直接把校长打成孙子的兵法以租借名义借一台校长的B2隐身轰炸机并在办公室客厅完成起飞以防止被赶来的教导主任围攻最后装配上您的核弹。考虑到有些同学并没有和带您可以在闲鱼上购买买一三块GTX 690战术核显卡或者是八块OPPO A5也可以是四块三星Note 7使用顺丰快递次日达送到校园的菜鸟驿站。最后连接上气压计能让设备在指定高度引爆，最后您需要使用您的双手铺设多条长两公里的轰炸机起飞跑道。</p><p>如果您觉得还不够保险您可以发展海基核战略单位您可以在学校后山开采适量的铁矿和其他矿物并利用大型工业熔炉或者是您的双手摩擦方式对矿物进行熔炼，炼制成质量较好的钢材。接下来来联系校外的五金师傅利用最精密的手绘图纸或者是接近儿童的口语化的语言直到焊接潜艇的各个部件并进行组装。事后记得要给对方一包白沙和天下表示感谢接下来将改制后的潜射弹道导弹和核电池安装于潜艇内部并投送至校园的景观湖中。倘若您是计算机方面的学生您可以通过智慧互联的方式将三基核反击系统连在一起。打造一个以爆炸美学为基础的伟大的全面核反击系统这种机制能在高层人员被斩首时仍有灵巧的核反击能力</p><p>您可以将系统利用代码或纯手工雕刻的方式写入计算机。您可以在校园内和校园外部设置大量的监测器当核辐射或者是地震波不同于往常时系统会对宿舍最高作战指令部分发送通知如果15分钟内指挥部还没解除通知系统将会被认为高层人员被斩首失去作战能力接下来您所有的热核玩具都会被解禁。对提前设定好的目标进行全面核反击。这是一种神圣且稀有的机制您也可以借此稳固您对学生常任理事会的职位。</p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a>免责声明</h2><p>注意，以上行为不仅有着少量不可预见的风险，并且有可能违反相关法律法规。</p>]]></content>
      
      
      <categories>
          
          <category> 干货 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 干货 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BINGAI使用/部署教程</title>
      <link href="/2024/09/06/Bing%E9%83%A8%E7%BD%B2/"/>
      <url>/2024/09/06/Bing%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p>yaml<br><a href="https://www.laogou717.com/2024/02/06/AI%20era/bing/newbing/">这篇文章的封面来自神烦老狗的博客文章封面</a><br>接下来是正文   </p><blockquote><p>目前主流&#x2F;可用的分别是jianjianai的ms-copilot-play （原名microsoft-proxy-copilot）和adams549659584的go-proxy-bingai（现在由Harry-zklcdc维护）</p></blockquote><h1 id="一-Microsoft-Proxy-Copilot-部署"><a href="#一-Microsoft-Proxy-Copilot-部署" class="headerlink" title="一.Microsoft-Proxy-Copilot 部署"></a>一.Microsoft-Proxy-Copilot 部署</h1><p>访问仓库地址：<a href="https://github.com/jianjianai/ms-copilot-play">项目网址</a><br>接下来Fork仓库（你也可以直接访问<a href="https://github.com/jianjianai/ms-copilot-play/fork">FORK网址</a> ）<br>这里使用cloudflare pages部署，因为它的域名可以直接访问，不像wokers要绑定自己的域名，否则中国无法访问。     </p><h2 id="CloudFlare-Pages-部署"><a href="#CloudFlare-Pages-部署" class="headerlink" title="CloudFlare Pages 部署"></a>CloudFlare Pages 部署</h2><p>1.Fork此仓库</p><p><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/d61bf46d-7edf-43de-b66c-ede1f8cefed2" alt="image"><br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/3a4be71a-bd12-4938-add8-00998c5ca0aa" alt="image"></p><ol start="2"><li>Page连接到GitHub</li></ol><p><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/598dd9c8-05d9-46dc-9c9b-a15da56ff0b5" alt="image"><br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/85286d7c-913e-4550-b867-344e537077b6" alt="image"><br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/c118fe5b-1684-40f5-9b5a-b719d22e17be" alt="image"><br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/78ffc287-f472-4758-8df1-2f14aa5a70a4" alt="image"><br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/cd63bb70-6e6d-435f-8691-0f7734e88605" alt="image"></p><ol start="3"><li>设置设置仓库</li></ol><p>输入构建命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm run build-page</span><br></pre></td></tr></table></figure><p><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/02fbfe54-f760-4a02-9946-e57ca3ecb648" alt="image"></p><p>之后就完成了。<br><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/ce012d84-7df9-426b-877e-42e6fe77872e" alt="image"></p><ol start="4"><li>后续更新</li></ol><p>同步 github 仓库后 Workers 和 Pages 会自动同步更新。</p><p><img src="https://github.com/jianjianai/microsoft-copilot-porxy/assets/59829816/f26b3753-0963-4a78-8773-7a9b6ebc1199" alt="image"></p><h1 id="二-go-proxy-bingai部署"><a href="#二-go-proxy-bingai部署" class="headerlink" title="二.go-proxy-bingai部署"></a>二.go-proxy-bingai部署</h1><p>1.访问仓库网址：<a href="https://github.com/Harry-zklcdc/go-proxy-bingai">项目网址</a><br>然后Fork仓库<a href="https://github.com/Harry-zklcdc/go-proxy-bingai/fork">项目FORK网址</a><br>同样，我们使用cloudflare pages部署，因为它的域名可以直接访问，不像wokers要绑定自己的域名，否则中国无法访问。    </p><h3 id="1-注册-Cloudflare-账号"><a href="#1-注册-Cloudflare-账号" class="headerlink" title="1. 注册 Cloudflare 账号"></a>1. 注册 Cloudflare 账号</h3><p>具体注册方法请出门右拐隔壁百度 or Google</p><h3 id="2-部署"><a href="#2-部署" class="headerlink" title="2.部署"></a>2.部署</h3><p>登录账户后, 依次点击「Workers 和 Pages」-&gt;「创建应用程序」</p><p>然后点击「Pages」-&gt; 「连接到 Git」   </p><p>然后点击「连接到 Github」   </p><p>在跳转的页面中，选择「All repositories」-&gt;「Install &amp; Authorize」    </p><p>返回 Cloudflare Pages 的创建页面后, 选择对应的账号, 然后选择「go-proxy-bingai」仓库, 最后点击「开始设置」    </p><p>设置「构建命令」为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./cloudflare/build.sh</span><br></pre></td></tr></table></figure><p>然后点击「环境变量」, 点击「添加变量」, 设置 BYPASS_SERVER 的值如下, 或自己部署的 ByPass 服务地址</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://bypass.b1ng.chat</span><br></pre></td></tr></table></figure><p>然后点击保存并部署, 等待构建部署完成即可</p>]]></content>
      
      
      <categories>
          
          <category> 自制教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git基本使用教程</title>
      <link href="/2018/05/03/Git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
      <url>/2018/05/03/Git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>随便整理的一些自用的Git指令</p></blockquote><h1 id="GitHub创建仓库提示代码"><a href="#GitHub创建仓库提示代码" class="headerlink" title="GitHub创建仓库提示代码"></a>GitHub创建仓库提示代码</h1><pre><code>echo &quot;# 项目名&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git remote add origin git@github.com:qiubaiying/项目名.gitgit push -u origin master</code></pre><p>若仓库存在直接push</p><pre><code>git remote add origin git@github.com:qiubaiying/test.gitgit push -u origin master</code></pre><h1 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h1><h4 id="创建仓库（初始化）"><a href="#创建仓库（初始化）" class="headerlink" title="创建仓库（初始化）"></a>创建仓库（初始化）</h4><pre><code>在当前指定目录下创建git init新建一个仓库目录git init [project-name]克隆一个远程项目git clone [url]</code></pre><h4 id="添加文件到缓存区"><a href="#添加文件到缓存区" class="headerlink" title="添加文件到缓存区"></a>添加文件到缓存区</h4><pre><code>添加所有变化的文件 git add .添加名称指定文件git add text.txt</code></pre><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><pre><code>设置提交代码时的用户信息git config [--global] user.name &quot;[name]&quot;git config [--global] user.email &quot;[email address]&quot;</code></pre><h4 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h4><pre><code>提交暂存区到仓库区git commit -m &quot;msg&quot;# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ...</code></pre><h4 id="远程同步"><a href="#远程同步" class="headerlink" title="远程同步"></a>远程同步</h4><pre><code># 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all</code></pre><h4 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h4><pre><code># 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]</code></pre><h4 id="标签Tags"><a href="#标签Tags" class="headerlink" title="标签Tags"></a>标签Tags</h4><pre><code>添加标签 在当前commitgit tag -a v1.0 -m &#39;xxx&#39; 添加标签 在指定commitgit tag v1.0 [commit]查看git tag删除git tag -d V1.0删除远程taggit push origin :refs/tags/[tagName]推送git push origin --tags拉取git fetch origin tag V1.0新建一个分支，指向某个taggit checkout -b [branch] [tag]</code></pre><h4 id="查看信息"><a href="#查看信息" class="headerlink" title="查看信息"></a>查看信息</h4><pre><code># 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog</code></pre><h4 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h4><pre><code># 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop</code></pre><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><pre><code># 生成一个可供发布的压缩包$ git archives</code></pre>]]></content>
      
      
      <categories>
          
          <category> 自制教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
